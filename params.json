{
  "name": "Poppy",
  "tagline": "A dataframe library for java",
  "body": "# Poppy\r\n*poppy* is dataframe library for java, which provides common SQL operations (e.g. select, from, where, group by, order by, distinct) to process data in java.\r\n\r\nUnlike other dataframe libraries, which keep all the data in memory, *poppy* process data in streaming manager. That is, it is more similar as [Java8 Stream library](https://docs.oracle.com/javase/8/docs/api/java/util/stream/package-summary.html), but relational version.\r\n\r\nHere is a simple example. We have a `Student` class\r\n\r\n```java\r\npublic class Student {\r\n    private int studentId;\r\n    private String name;\r\n    private int grade;\r\n    private int room;\r\n    private int height;\r\n    private int weight;\r\n    ...\r\n}\r\n```\r\n\r\nIn SQL, we have a query like this\r\n\r\n```sql\r\nselect \r\n    grade, \r\n    room, \r\n    avg(weight) as weight, \r\n    avg(height) as height\r\nfrom Student\r\ngroup by grade, room\r\norder by grade, room\r\n```\r\n\r\nHere is the *Poppy*'s version \r\n\r\n```java\r\nList<Student> students = ...;\r\n\r\nDataFrame\r\n.from(students, Student.class)\r\n.groupby(\"grade\", \"room\")\r\n.aggregate(\r\n    avgLong(\"weight\").as(\"weight\"),\r\n    avgLong(\"height\").as(\"height\"))\r\n.sort(\"grade\", \"room\")\r\n.print();\r\n```\r\n\r\n\r\n\r\n# Getting Started\r\n\r\n## Requirement\r\nJava 8 or higher\r\n\r\n## Dependency\r\n\r\nMaven\r\n\r\n```\r\n<dependency>\r\n  <groupId>io.tenmax</groupId>\r\n  <artifactId>poppy</artifactId>\r\n  <version>0.1.7</version>\r\n  <type>pom</type>\r\n</dependency>\r\n```\r\n\r\nGradle\r\n\r\n```\r\ncompile 'io.tenmax:poppy:0.1.7'\r\n```\r\n## Features\r\n\r\n1. Support the most common operations in SQL. e.g. select, from, where, group by, order by, distinct\r\n2. Support the most common aggregation functions in SQL. e.g. *avg()*, *sum()*, *count()*, *min()*, *max()*\r\n3. **Custom aggregation functions.** by  [java.util.stream.Collector](https://docs.oracle.com/javase/8/docs/api/java/util/stream/Collector.html)\r\n4. **Partition support.** Partition is the unit of parallelism. Multiple partitions allow you processing data concurrently.\r\n5. **Multi-threaded support**. For CPU-bound jobs, it leverages all your CPU resources for better performance; for IO-bound jobs, it reduces the waiting time, and take adventages of better concurrency.\r\n6. Suitable for both **batch** and **streaming** scenario.\r\n7. **Lightweight**. Comparing to [Spark DataFrame API](https://spark.apache.org/docs/latest/sql-programming-guide.html), it is much more lightweight to embed in your application.\r\n8. **Stream-based design**. Comparing to [joinery](https://github.com/cardillo/joinery), which keeps the whole data in memory. *Poppy*'s streaming behaviour allows limited memory to process huge volume of data.\r\n\r\n## Documentation\r\n\r\n[JavaDoc](docs/javadoc/index.html)\r\n\r\n# Input\r\n\r\nThere are two kinds of input.\r\n\r\n1. DataFrame.from(Class\\<T> clazz, java.util.Iterable... iterables)\r\n2. DataFrame.from(io.tenmax.DataSource dataSource)\r\n\r\nThe first one uses [JavaBean Conventions](https://en.wikipedia.org/wiki/JavaBeans) to define the table schema. This is the simplest way to create a dataframe\r\n\r\n```\r\nList<Student> students = ...;\r\n\r\nDataFrame df = DataFrame.from(Student.class, students);\r\n```\r\n\r\nThe second one allows you most flexible way to define the data source. In data source, it should define \r\n\r\n1. The schema (by a list of columns)\r\n2. Partition count\r\n3. The iterators for specified partition\r\n4. The mapping from one data to data in all columns.\r\n\r\n```\r\nDataSource dataSource = ...\r\n\r\nDataFrame df = DataFrame.from(dataSource);\r\n```\r\n\r\n# Output\r\n\r\nThere are several ways to output the data\r\n\r\n1. Iterator\r\n2. forEach\r\n3. toList\r\n4. toMap\r\n5. DataFrame.to(DataSink dataSink)\r\n\r\nThe first two methods are provided from *java.util.Iterable* interface. So you can use `for(T t: dataFrame)` to iterate through the dataframe.\r\n\r\n`toList` and `toMap` provide quick methods to output dataframe to collections. Both provide the list version and reflection version. The later exports the data by the [JavaBean conventions](https://en.wikipedia.org/wiki/JavaBeans). `toMap` method should define grouping columns by `groupby` method to define the key of map.\r\n\r\nThe latest version provides the most flexible version of output. Th results are called back directly in the multi-threaded context, offering the best level of parallelism to output the results to destination, just like Hadoop does.\r\n\r\n# Operations\r\n\r\n## Project\r\nProject is the same as `select` in SQL. Project maps one column to another name, or merges multiple columns to one column. In the following example, we use SQL as analogy to explain each operation.\r\n\r\n*SQL*\r\n\r\n```sql\r\nselect name, weight, height from student;\r\n```\r\n\r\n*Poppy*\r\n\r\n```java\r\ndf.project(\"name\", \"weight\", \"height\");\r\n```\r\n\r\nAnother example is to alias a name to a column.\r\n\r\n*SQL*\r\n\r\n```sql\r\nselect \r\n    name, \r\n    weight as w, \r\n    height / 10 as h\r\nfrom student;\r\n```\r\n\r\n*Poppy*\r\n\r\n```java\r\nimport static io.tenmax.poppy.SpecUtils.*;\r\n\r\ndf.project(\r\n   col(\"name\"),\r\n   colMap(\"weight\").as(\"w\"),\r\n   colMap(\"height\", Float.class, (Integer height) -> (height / 10f)).as(\"h\"))\r\n```\r\n\r\n## Filter\r\nFilter is the same as `where` or `having` in SQL. Filter is used to keep the rows which pass the rule.\r\n\r\n*SQL*\r\n\r\n```sql\r\nselect * from Student where height > 170;\r\n```\r\n\r\n*Poppy*\r\n\r\n```java\r\ndf.filter(row -> row.getInteger(\"height\") > 170);\r\n```\r\n\r\n\r\n## Aggregation\r\n\r\n*SQL*\r\n\r\n```sql\r\nselect \r\n    count(*) as c,\r\n    avg(weight) as weight,\r\n    avg(height) as height\r\nfrom Student;\r\n```\r\n*Poppy*\r\n\r\n```java\r\ndf.aggregate(\r\n\tcount().as(\"c\")\r\n    avgLong(\"weight\").as(\"weight\"),\r\n    avgLong(\"height\").as(\"height\")\r\n);\r\n```\r\n\r\nYou can define custom aggregation by Java8 [Collector](https://docs.oracle.com/javase/8/docs/api/java/util/stream/Collector.html) interface.\r\n\r\n*Poppy*\r\n\r\n```java\r\ndf.aggregate(\r\n    aggreMap(\"weight\", Integer.class, Collectors.summingInt((Integer i) -> i)).as(\"wi\"))\r\n)\r\n```\r\n\r\nOf course, poppy supports aggregate with grouping.\r\n\r\n*SQL*\r\n```sql\r\nselect \r\n    grade, \r\n    room, \r\n    avg(weight) as weight, \r\n    avg(height) as height\r\nfrom Student\r\ngroup by grade, room\r\n```\r\n*Poppy*\r\n\r\n```java\r\ndf\r\n.groupby(\"grade\",\"room\")\r\n.aggregate(\r\n    avgLong(\"weight\").as(\"weight\"),\r\n    avgLong(\"height\").as(\"height\"));\r\n```\r\n\r\n## Sort\r\n\r\nSort the dataframe by columns.\r\n\r\n*SQL*\r\n\r\n```sql\r\nselect *\r\nfrom Student\r\norder by weight, height;\r\n```\r\n*Poppy*\r\n\r\n```java\r\ndf.sort(\"weight\", \"height\");\r\n```\r\n\r\nSpecify the sorting orders.\r\n\r\n*SQL*\r\n\r\n```sql\r\nselect *\r\nfrom Student\r\norder by weight asc, height desc;\r\n```\r\n*Poppy*\r\n\r\n```java\r\nimport static io.tenmax.poppy.SpecUtils.*;\r\n\r\ndf.sort(asc(\"weight\"), desc(\"height\"));\r\n```\r\n\r\n\r\n## Distinct\r\n\r\nSelect the unique records by columns.\r\n\r\n*SQL*\r\n\r\n```sql\r\nselect distinct grade, room from Student;\r\n```\r\n*Poppy*\r\n\r\n```java\r\ndf.distinct(\"grade\", \"room\");\r\n```\r\n\r\n# Partition and Parallelism\r\n\r\nPartition is the unit of parallelism. To leverage the multicore computing power, we can provide more than one partitions in the data sources. And in dataframe, we use the `parallel(n)` to define number of threads running in the thread pool\r\n\r\n```java\r\nDataFrame\r\n.from(myDataSource)\r\n.parallel(4)\r\n.aggregate(...)\r\n.forEach(row -> {/*...*/})\r\n```\r\n\r\n## Execution Context\r\n\r\n*Poppy* introduces the concept of execution context. One execution context contains a thread pool with *n* threads and *m* partitions. It treat one partition as a task, and one thread only processses task at the same time. Internally, it make the projection, filtering, accumulation of aggregation as a pipeline. Once all tasks complete, the thread pool shutdown and release all the resources. \r\n\r\nThe following diagram is an example of multiple partition with 3 threads in pool. And the final results would pipe the result to the queue and be pulled by the caller thread. \r\n\r\n![](assets/executionContext.png)\r\n\r\nAnother case is the DataFrame output the result to a DataSink directly. Here the result is invoked in the threads of execution context.\r\n\r\n![](assets/executionContext2.png)\r\n\r\nIf there is no parallel threads defined in the execution context, the default behaviour is to use the caller thread to iterate through all the partition sequentially. So there is no thread spawned in this case.\r\n\r\n![](assets/executionContext3.png)\r\n\r\nFor some operations, they would create a new execution context. Such as, aggregation, sort, distinct. Currently, they would create a new context with only one partition. The following example is a aggregation example, the partition data would be accumulated as a accumulated value and be combined all the results to the final result.\r\n\r\n![](assets/executionContext4.png)\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}